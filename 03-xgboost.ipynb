{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set notebook properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'../data_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_features = pd.read_csv(os.path.join(DATA_PATH, 'training_set_features.csv'))\n",
    "training_set_labels = pd.read_csv(os.path.join(DATA_PATH, 'training_set_labels.csv'))\n",
    "test_set_features = pd.read_csv(os.path.join(DATA_PATH, 'test_set_features.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df):\n",
    "    \n",
    "    cols_to_process =  ['h1n1_concern', 'h1n1_knowledge',\n",
    "                        'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
    "                        'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
    "                        'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'age_group',\n",
    "                        'education', 'race', 'sex', 'income_poverty', 'marital_status',\n",
    "                        'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa',\n",
    "                        'household_adults', 'household_children', 'employment_industry',\n",
    "                        'employment_occupation']\n",
    "    \n",
    "    for i in cols_to_process:\n",
    "        df[i] = [f'{i}_' + str(x)  for x in df[i]]\n",
    "        \n",
    "    concat_list = []\n",
    "    for i in cols_to_process:\n",
    "        concat_list.append(pd.get_dummies(df[i]))\n",
    "        \n",
    "    one_hot_encoded = pd.concat(concat_list, axis=1)\n",
    "    df = df.drop(columns=cols_to_process)\n",
    "    df_concatenated = pd.concat([df, one_hot_encoded], axis=1)\n",
    "        \n",
    "    return df_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_features(training_set_features).iloc[:,1:].fillna(0)\n",
    "y_h1n1 = training_set_labels['h1n1_vaccine']\n",
    "y_seasonal = training_set_labels['seasonal_vaccine']\n",
    "X_test = process_features(test_set_features).iloc[:,1:].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns = ['col_' + str(x) for x in range(len(X.columns))]\n",
    "X_test.columns = ['col_' + str(x) for x in range(len(X_test.columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParameterTuning(X_train, y_train):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': [1, 3, 5]\n",
    "    }\n",
    "    \n",
    "    xgb_model = XGBClassifier()\n",
    "\n",
    "    gsearch = GridSearchCV(estimator = xgb_model,\n",
    "                           param_grid = param_tuning,                        \n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "    gsearch.fit(X_train,y_train)\n",
    "\n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hyperParameterTuning(X, y_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameterTuning(X, y_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:35:08] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, eval_metric='auc',\n",
       "              gamma=1, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.001, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=200, n_jobs=4, nthread=4,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=0.8, tree_method='exact',\n",
       "              validate_parameters=1, verbose=1, verbosity=None)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_h1n1 = XGBClassifier(learning_rate=0.001, n_estimators=200, max_depth=4,\n",
    "                         min_child_weight=5, gamma=1, subsample=0.8, colsample_bytree=0.8,\n",
    "                         objective= 'binary:logistic', nthread=4, verbose=1, eval_metric='auc')\n",
    "xgb_h1n1.fit(X, y_h1n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:35:12] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:541: \n",
      "Parameters: { verbose } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.8, eval_metric='auc',\n",
       "              gamma=1, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.001, max_delta_step=0,\n",
       "              max_depth=4, min_child_weight=5, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=200, n_jobs=4, nthread=4,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=0.8, tree_method='exact',\n",
       "              validate_parameters=1, verbose=1, verbosity=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_seasonal = XGBClassifier(learning_rate=0.001, n_estimators=200, max_depth=4,\n",
    "                             min_child_weight=5, gamma=1, subsample=0.8, colsample_bytree=0.8,\n",
    "                             objective= 'binary:logistic', nthread=4, verbose=1, eval_metric='auc')\n",
    "xgb_seasonal.fit(X, y_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_h1n1 = xgb_h1n1.predict_proba(X_test)\n",
    "probability_h1n1 = [x[1] for x in probability_h1n1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_seasonal = xgb_seasonal.predict_proba(X_test)\n",
    "probability_seasonal = [x[1] for x in probability_seasonal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['respondent_id'] = test_set_features['respondent_id']\n",
    "submission['h1n1_vaccine'] = probability_h1n1\n",
    "submission['seasonal_vaccine'] = probability_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = os.path.join(r'../output', 'xgboost2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(outpath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
