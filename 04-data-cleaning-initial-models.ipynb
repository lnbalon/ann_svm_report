{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set notebook properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r'../data_source'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_features = pd.read_csv(os.path.join(DATA_PATH, 'training_set_features.csv'))\n",
    "training_set_labels = pd.read_csv(os.path.join(DATA_PATH, 'training_set_labels.csv'))\n",
    "test_set_features = pd.read_csv(os.path.join(DATA_PATH, 'test_set_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = training_set_features.merge(training_set_labels, on=['respondent_id'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(df):\n",
    "    \n",
    "    cols_to_process =  ['h1n1_concern', 'h1n1_knowledge',\n",
    "                        'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
    "                        'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective',\n",
    "                        'opinion_seas_risk', 'opinion_seas_sick_from_vacc', 'age_group',\n",
    "                        'education', 'race', 'sex', 'income_poverty', 'marital_status',\n",
    "                        'rent_or_own', 'employment_status', 'hhs_geo_region', 'census_msa',\n",
    "                        'household_adults', 'household_children', 'employment_industry',\n",
    "                        'employment_occupation']\n",
    "    \n",
    "    for i in cols_to_process:\n",
    "        df[i] = [f'{i}_' + str(x)  for x in df[i]]\n",
    "        \n",
    "    concat_list = []\n",
    "    for i in cols_to_process:\n",
    "        concat_list.append(pd.get_dummies(df[i]))\n",
    "        \n",
    "    one_hot_encoded = pd.concat(concat_list, axis=1)\n",
    "    df = df.drop(columns=cols_to_process)\n",
    "    df_concatenated = pd.concat([df, one_hot_encoded], axis=1)\n",
    "        \n",
    "    return df_concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = process_features(training_set_features).iloc[:,1:].fillna(0)\n",
    "y_h1n1 = training_set_labels['h1n1_vaccine']\n",
    "y_seasonal = training_set_labels['seasonal_vaccine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = process_features(test_set_features).iloc[:,1:].fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train, X_test, y_train_h1n1, y_test_h1n1 = train_test_split(X, y_h1n1, \n",
    "                                                              test_size=0.3, \n",
    "                                                              random_state=109)\n",
    "\n",
    "X_train, X_test, y_train_seasonal, y_test_seasonal = train_test_split(X, y_seasonal, \n",
    "                                                              test_size=0.3, \n",
    "                                                              random_state=109)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X,y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=157, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X, y, epochs=20, batch_size=10, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model2(X,y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(45, input_dim=157, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X, y, epochs=20, batch_size=10, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model3(X,y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=157, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(30, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X, y, epochs=20, batch_size=10, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model3(X,y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=157, activation='relu'))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(30))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Dense(30))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X, y, epochs=20, batch_size=10, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model4(X,y):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(30, input_dim=157, activation='linear'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X, y, epochs=20, batch_size=10, verbose=1)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperParameterTuning(X_train, y_train):\n",
    "    param_tuning = {\n",
    "        'learning_rate': [0.01, 0.1],\n",
    "        'max_depth': [3, 5, 7, 10],\n",
    "        'min_child_weight': [1, 3, 5],\n",
    "        'subsample': [0.5, 0.7],\n",
    "        'colsample_bytree': [0.5, 0.7],\n",
    "        'n_estimators' : [100, 200, 500],\n",
    "        'objective': ['binary:logistic']\n",
    "    }\n",
    "    X_train.columns = ['col_' + str(x) for x in range(len(X_train.columns))]\n",
    "\n",
    "    xgb_model = XGBClassifier()\n",
    "\n",
    "    gsearch = GridSearchCV(estimator = xgb_model,\n",
    "                           param_grid = param_tuning,                        \n",
    "                           cv = 5,\n",
    "                           n_jobs = -1,\n",
    "                           verbose = 1)\n",
    "\n",
    "    gsearch.fit(X_train,y_train)\n",
    "\n",
    "    return gsearch.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "hyperParameterTuning(X, y_h1n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperParameterTuning(X, y_seasonal)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def train_model5(X,y):\n",
    "    X.columns = ['col_' + str(x) for x in range(len(X.columns))]\n",
    "    xgb = XGBClassifier(learning_rate=0.1, n_estimators=140, max_depth=5,\n",
    "                        min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "                        objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27)\n",
    "    xgb.fit(X, y)\n",
    "    \n",
    "    return xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:47:38] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "trained_model_h1n1 = train_model5(X, y_h1n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:47:41] WARNING: /tmp/build/80754af9/xgboost-split_1619724447847/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "trained_model_seasonal = train_model5(X, y_seasonal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_h1n1 = trained_model_h1n1.predict_classes(X_test)\n",
    "X_test.columns = ['col_' + str(x) for x in range(len(X_test.columns))]\n",
    "probability_h1n1 = trained_model_h1n1.predict_proba(X_test)\n",
    "probability_h1n1 = [x[1] for x in probability_h1n1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions_seasonal = trained_model_seasonal.predict_classes(X_test)\n",
    "X_test.columns = ['col_' + str(x) for x in range(len(X_test.columns))]\n",
    "probability_seasonal = trained_model_seasonal.predict_proba(X_test)\n",
    "probability_seasonal = [x[1] for x in probability_seasonal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['respondent_id'] = test_set_features['respondent_id']\n",
    "submission['h1n1_vaccine'] = probability_h1n1\n",
    "submission['seasonal_vaccine'] = probability_seasonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = os.path.join(r'../output', 'sub7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(outpath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
